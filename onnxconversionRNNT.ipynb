{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Q8oC2vEIoXc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8wxRvrIIqZw"
      },
      "source": [
        "# We need to install the dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xb5YZqPPxA6",
        "outputId": "5b2fd5ed-0ed6-42dd-9085-fd772e69b7d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NeMo'...\n",
            "remote: Enumerating objects: 79519, done.\u001b[K\n",
            "remote: Counting objects: 100% (224/224), done.\u001b[K\n",
            "remote: Compressing objects: 100% (62/62), done.\u001b[K\n",
            "remote: Total 79519 (delta 186), reused 178 (delta 162), pack-reused 79295 (from 3)\u001b[K\n",
            "Receiving objects: 100% (79519/79519), 141.13 MiB | 9.31 MiB/s, done.\n",
            "Resolving deltas: 100% (57717/57717), done.\n",
            "Already on 'nemo-v2'\n",
            "Your branch is up to date with 'origin/nemo-v2'.\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.1.1\n",
            "Uninstalling stuff\n",
            "\u001b[33mWARNING: Skipping nemo_toolkit as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping sacrebleu as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping nemo_asr as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping nemo_nlp as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping nemo_tts as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling nemo\n",
            "Obtaining file:///content/NeMo\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting huggingface_hub==0.23.2 (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading huggingface_hub-0.23.2-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (2.0.2)\n",
            "Collecting onnx>=1.7.0 (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (2.9.0.post0)\n",
            "Collecting ruamel.yaml (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading ruamel.yaml-0.18.14-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (1.6.1)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (75.2.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (2.18.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (1.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (4.67.1)\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (3.2.0)\n",
            "Collecting wget (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (1.17.2)\n",
            "Collecting black==19.10b0 (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading black-19.10b0-py36-none-any.whl.metadata (58 kB)\n",
            "Collecting click==8.0.2 (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading click-8.0.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting isort<6.0.0,>5.1.0 (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading isort-5.13.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting parameterized (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (8.3.5)\n",
            "Collecting pytest-runner (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading pytest_runner-6.0.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (8.2.3)\n",
            "Collecting sphinxcontrib-bibtex (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading sphinxcontrib_bibtex-2.6.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (0.20.1)\n",
            "Collecting hydra-core<=1.3.2,>1.3 (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: omegaconf<=2.3 in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (2.3.0)\n",
            "Collecting pytorch-lightning>=2.2.1 (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting torchmetrics>=0.11.0 (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading torchmetrics-1.7.3-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: transformers>=4.36.0 in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (4.52.4)\n",
            "Collecting webdataset>=0.2.86 (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading webdataset-0.2.111-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (2.14.4)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (7.5.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (2.2.2)\n",
            "Collecting sacremoses>=0.0.43 (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: sentencepiece<1.0.0 in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (0.2.0)\n",
            "Collecting braceexpand (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading braceexpand-0.1.7-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (0.8.1)\n",
            "Collecting g2p_en (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading g2p_en-2.1.0-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (7.7.1)\n",
            "Collecting jiwer (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting kaldi-python-io (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading kaldi-python-io-1.2.2.tar.gz (8.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting kaldiio (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading kaldiio-2.18.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting lhotse>=1.20.0 (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading lhotse-1.30.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: librosa>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (0.11.0)\n",
            "Collecting marshmallow (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading marshmallow-4.0.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (3.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (24.2)\n",
            "Collecting pyannote.core (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading pyannote.core-5.0.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting pyannote.metrics (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading pyannote.metrics-3.2.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (0.25.1)\n",
            "Collecting pyloudnorm (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading pyloudnorm-0.1.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting resampy (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (1.15.3)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (0.13.1)\n",
            "Collecting sox (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading sox-1.5.0.tar.gz (63 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting texterrors (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading texterrors-1.0.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting boto3 (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading boto3-1.38.38-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (0.8.1)\n",
            "Collecting faiss-cpu (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting fasttext (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting flask_restful (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading Flask_RESTful-0.3.10-py2.py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting ftfy (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (5.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (3.14.0)\n",
            "Collecting ijson (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading ijson-3.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (0.42.1)\n",
            "Collecting markdown2 (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading markdown2-2.5.3-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting megatron_core==0.2.0 (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading megatron_core-0.2.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nltk>=3.6.5 in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (3.9.1)\n",
            "Collecting opencc<1.1.7 (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading OpenCC-1.1.6-cp311-cp311-manylinux1_x86_64.whl.metadata (12 kB)\n",
            "Collecting pangu (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading pangu-4.0.6.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting rapidfuzz (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting rouge_score (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacrebleu (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (4.1.0)\n",
            "Collecting tensorstore<0.1.46 (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading tensorstore-0.1.45-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
            "Collecting zarr (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading zarr-3.0.8-py3-none-any.whl.metadata (10.0 kB)\n",
            "Collecting attrdict (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading attrdict-2.0.1-py2.py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting kornia (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading kornia-0.8.1-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting nemo_text_processing (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading nemo_text_processing-1.1.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting pypinyin (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading pypinyin-0.54.0-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pypinyin-dict (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading pypinyin_dict-0.9.0-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting progress>=1.5 (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading progress-1.6.tar.gz (7.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tabulate>=0.8.7 in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (0.9.0)\n",
            "Collecting textdistance>=4.1.5 (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading textdistance-4.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting addict (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting clip (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading clip-0.2.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: diffusers>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (0.33.1)\n",
            "Collecting einops_exts (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading einops_exts-0.0.4-py3-none-any.whl.metadata (621 bytes)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (from nemo_toolkit==1.23.0rc0) (2.37.0)\n",
            "Collecting nerfacc>=0.5.3 (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading nerfacc-0.5.3-py3-none-any.whl.metadata (915 bytes)\n",
            "Collecting open_clip_torch (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading open_clip_torch-2.32.0-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting PyMCubes (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading PyMCubes-0.1.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (868 bytes)\n",
            "Collecting taming-transformers (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading taming_transformers-0.0.1-py3-none-any.whl.metadata (499 bytes)\n",
            "Collecting torchdiffeq (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading torchdiffeq-0.2.5-py3-none-any.whl.metadata (440 bytes)\n",
            "Collecting torchsde (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting trimesh (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading trimesh-4.6.12-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.11/dist-packages (from black==19.10b0->nemo_toolkit==1.23.0rc0) (25.3.0)\n",
            "Collecting appdirs (from black==19.10b0->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: toml>=0.9.4 in /usr/local/lib/python3.11/dist-packages (from black==19.10b0->nemo_toolkit==1.23.0rc0) (0.10.2)\n",
            "Collecting typed-ast>=1.4.0 (from black==19.10b0->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading typed_ast-1.5.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from black==19.10b0->nemo_toolkit==1.23.0rc0) (2024.11.6)\n",
            "Collecting pathspec<1,>=0.6 (from black==19.10b0->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.23.2->nemo_toolkit==1.23.0rc0) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.23.2->nemo_toolkit==1.23.0rc0) (2025.3.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.23.2->nemo_toolkit==1.23.0rc0) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.23.2->nemo_toolkit==1.23.0rc0) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub==0.23.2->nemo_toolkit==1.23.0rc0) (4.14.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core<=1.3.2,>1.3->nemo_toolkit==1.23.0rc0) (4.9.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers>=0.19.3->nemo_toolkit==1.23.0rc0) (8.7.0)\n",
            "INFO: pip is looking at multiple versions of diffusers to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting diffusers>=0.19.3 (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading diffusers-0.33.0-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading diffusers-0.32.2-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers>=0.19.3->nemo_toolkit==1.23.0rc0) (0.5.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers>=0.19.3->nemo_toolkit==1.23.0rc0) (11.2.1)\n",
            "INFO: pip is looking at multiple versions of jiwer to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jiwer (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading jiwer-3.0.5-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading jiwer-3.0.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading jiwer-3.0.3-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading jiwer-3.0.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading jiwer-3.0.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading jiwer-3.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading jiwer-2.6.0-py3-none-any.whl.metadata (14 kB)\n",
            "INFO: pip is still looking at multiple versions of jiwer to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading jiwer-2.5.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting rapidfuzz (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading rapidfuzz-2.13.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from lhotse>=1.20.0->nemo_toolkit==1.23.0rc0) (3.0.1)\n",
            "Collecting cytoolz>=0.10.1 (from lhotse>=1.20.0->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading cytoolz-1.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting intervaltree>=3.1.0 (from lhotse>=1.20.0->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lilcom>=1.1.0 (from lhotse>=1.20.0->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading lilcom-1.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from cytoolz>=0.10.1->lhotse>=1.20.0->nemo_toolkit==1.23.0rc0) (0.12.1)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from intervaltree>=3.1.0->lhotse>=1.20.0->nemo_toolkit==1.23.0rc0) (2.4.0)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->nemo_toolkit==1.23.0rc0) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->nemo_toolkit==1.23.0rc0) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->nemo_toolkit==1.23.0rc0) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->nemo_toolkit==1.23.0rc0) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->nemo_toolkit==1.23.0rc0) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->nemo_toolkit==1.23.0rc0) (1.1.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nemo_toolkit==1.23.0rc0) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nemo_toolkit==1.23.0rc0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nemo_toolkit==1.23.0rc0) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nemo_toolkit==1.23.0rc0) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nemo_toolkit==1.23.0rc0) (3.2.3)\n",
            "Requirement already satisfied: rich>=12 in /usr/local/lib/python3.11/dist-packages (from nerfacc>=0.5.3->nemo_toolkit==1.23.0rc0) (13.9.4)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->nemo_toolkit==1.23.0rc0) (0.43.0)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from onnx>=1.7.0->nemo_toolkit==1.23.0rc0) (5.29.5)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa>=0.10.0->nemo_toolkit==1.23.0rc0) (4.3.8)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->nemo_toolkit==1.23.0rc0) (1.17.0)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning>=2.2.1->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=2.2.1->nemo_toolkit==1.23.0rc0) (3.11.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.2.1->nemo_toolkit==1.23.0rc0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.2.1->nemo_toolkit==1.23.0rc0) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.2.1->nemo_toolkit==1.23.0rc0) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.2.1->nemo_toolkit==1.23.0rc0) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.2.1->nemo_toolkit==1.23.0rc0) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.2.1->nemo_toolkit==1.23.0rc0) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.2.1->nemo_toolkit==1.23.0rc0) (3.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.23.2->nemo_toolkit==1.23.0rc0) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.23.2->nemo_toolkit==1.23.0rc0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub==0.23.2->nemo_toolkit==1.23.0rc0) (2025.6.15)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12->nerfacc>=0.5.3->nemo_toolkit==1.23.0rc0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12->nerfacc>=0.5.3->nemo_toolkit==1.23.0rc0) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12->nerfacc>=0.5.3->nemo_toolkit==1.23.0rc0) (0.1.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->nemo_toolkit==1.23.0rc0) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile->nemo_toolkit==1.23.0rc0) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile->nemo_toolkit==1.23.0rc0) (2.22)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->nemo_toolkit==1.23.0rc0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->nemo_toolkit==1.23.0rc0) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->nemo_toolkit==1.23.0rc0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->nemo_toolkit==1.23.0rc0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->nemo_toolkit==1.23.0rc0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->nemo_toolkit==1.23.0rc0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->nemo_toolkit==1.23.0rc0) (1.3.0)\n",
            "INFO: pip is looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting transformers>=4.36.0 (from nemo_toolkit==1.23.0rc0)\n",
            "  Downloading transformers-4.52.3-py3-none-any.whl.metadata (40 kB)\n",
            "  Downloading transformers-4.52.2-py3-none-any.whl.metadata (40 kB)\n",
            "  Downloading transformers-4.52.1-py3-none-any.whl.metadata (38 kB)\n",
            "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
            "  Downloading transformers-4.51.2-py3-none-any.whl.metadata (38 kB)\n",
            "  Downloading transformers-4.51.1-py3-none-any.whl.metadata (38 kB)\n",
            "  Downloading transformers-4.51.0-py3-none-any.whl.metadata (38 kB)\n",
            "INFO: pip is still looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading transformers-4.50.3-py3-none-any.whl.metadata (39 kB)\n",
            "  Downloading transformers-4.50.2-py3-none-any.whl.metadata (39 kB)\n",
            "  Downloading transformers-4.50.1-py3-none-any.whl.metadata (39 kB)\n",
            "  Downloading transformers-4.50.0-py3-none-any.whl.metadata (39 kB)\n",
            "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n",
            "  Downloading transformers-4.48.2-py3-none-any.whl.metadata (44 kB)\n",
            "  Downloading transformers-4.48.1-py3-none-any.whl.metadata (44 kB)\n",
            "  Downloading transformers-4.48.0-py3-none-any.whl.metadata (44 kB)\n",
            "  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n",
            "  Downloading transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n",
            "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
            "Collecting tokenizers<0.21,>=0.20 (from transformers>=4.36.0->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting botocore<1.39.0,>=1.38.38 (from boto3->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading botocore-1.38.38-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading s3transfer-0.13.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->nemo_toolkit==1.23.0rc0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->nemo_toolkit==1.23.0rc0) (0.3.7)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->nemo_toolkit==1.23.0rc0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets->nemo_toolkit==1.23.0rc0) (0.70.15)\n",
            "Collecting pybind11>=2.2 (from fasttext->nemo_toolkit==1.23.0rc0)\n",
            "  Using cached pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting aniso8601>=0.82 (from flask_restful->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading aniso8601-10.0.1-py2.py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.11/dist-packages (from flask_restful->nemo_toolkit==1.23.0rc0) (3.1.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from flask_restful->nemo_toolkit==1.23.0rc0) (2025.2)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask_restful->nemo_toolkit==1.23.0rc0) (1.9.0)\n",
            "INFO: pip is looking at multiple versions of flask to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting Flask>=0.8 (from flask_restful->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading flask-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask_restful->nemo_toolkit==1.23.0rc0) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask_restful->nemo_toolkit==1.23.0rc0) (2.2.0)\n",
            "  Downloading flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
            "  Downloading flask-3.0.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading flask-3.0.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading flask-3.0.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading flask-2.3.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading Flask-2.3.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "INFO: pip is still looking at multiple versions of flask to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading Flask-2.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading Flask-2.3.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading Flask-2.2.5-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->nemo_toolkit==1.23.0rc0) (3.0.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->nemo_toolkit==1.23.0rc0) (0.2.13)\n",
            "Collecting distance>=0.1.3 (from g2p_en->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading Distance-0.1.3.tar.gz (180 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more_itertools>=8.5.0 in /usr/local/lib/python3.11/dist-packages (from inflect->nemo_toolkit==1.23.0rc0) (10.7.0)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from inflect->nemo_toolkit==1.23.0rc0) (4.4.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown->nemo_toolkit==1.23.0rc0) (4.13.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown->nemo_toolkit==1.23.0rc0) (2.7)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers>=0.19.3->nemo_toolkit==1.23.0rc0) (3.23.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->nemo_toolkit==1.23.0rc0) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->nemo_toolkit==1.23.0rc0) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->nemo_toolkit==1.23.0rc0) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->nemo_toolkit==1.23.0rc0) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->nemo_toolkit==1.23.0rc0) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->nemo_toolkit==1.23.0rc0) (3.0.15)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit==1.23.0rc0) (6.5.7)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->nemo_toolkit==1.23.0rc0) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->nemo_toolkit==1.23.0rc0) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->nemo_toolkit==1.23.0rc0) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->nemo_toolkit==1.23.0rc0) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->nemo_toolkit==1.23.0rc0) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->nemo_toolkit==1.23.0rc0) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->nemo_toolkit==1.23.0rc0) (6.4.2)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit==1.23.0rc0) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit==1.23.0rc0) (3.0.51)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit==1.23.0rc0) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit==1.23.0rc0) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets->nemo_toolkit==1.23.0rc0) (0.8.4)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->nemo_toolkit==1.23.0rc0) (5.8.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit==1.23.0rc0) (25.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit==1.23.0rc0) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit==1.23.0rc0) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit==1.23.0rc0) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit==1.23.0rc0) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit==1.23.0rc0) (0.22.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit==1.23.0rc0) (1.3.1)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit==1.23.0rc0) (0.2.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit==1.23.0rc0) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit==1.23.0rc0) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit==1.23.0rc0) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit==1.23.0rc0) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit==1.23.0rc0) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit==1.23.0rc0) (1.5.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit==1.23.0rc0) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit==1.23.0rc0) (1.4.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit==1.23.0rc0) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit==1.23.0rc0) (4.24.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit==1.23.0rc0) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit==1.23.0rc0) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit==1.23.0rc0) (0.25.1)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit==1.23.0rc0) (1.16.0)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit==1.23.0rc0) (4.9.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit==1.23.0rc0) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit==1.23.0rc0) (1.3.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets->nemo_toolkit==1.23.0rc0) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit==1.23.0rc0) (21.2.0)\n",
            "Collecting kornia_rs>=0.1.9 (from kornia->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading kornia_rs-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting cdifflib (from nemo_text_processing->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading cdifflib-1.2.9.tar.gz (12 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pynini==2.1.6.post1 (from nemo_text_processing->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading pynini-2.1.6.post1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from open_clip_torch->nemo_toolkit==1.23.0rc0) (0.21.0+cu124)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from open_clip_torch->nemo_toolkit==1.23.0rc0) (1.0.15)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->nemo_toolkit==1.23.0rc0) (2025.2)\n",
            "Collecting pyannote.database>=4.0.1 (from pyannote.metrics->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading pyannote.database-5.1.3-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting docopt>=0.6.2 (from pyannote.metrics->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit==1.23.0rc0) (0.16.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit==1.23.0rc0) (1.5.4)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.11/dist-packages (from pyloudnorm->nemo_toolkit==1.23.0rc0) (1.0.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest->nemo_toolkit==1.23.0rc0) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest->nemo_toolkit==1.23.0rc0) (1.6.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->nemo_toolkit==1.23.0rc0) (1.7.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score->nemo_toolkit==1.23.0rc0) (1.4.0)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting portalocker (from sacrebleu->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting colorama (from sacrebleu->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu->nemo_toolkit==1.23.0rc0) (5.4.0)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.11/dist-packages (from sphinx->nemo_toolkit==1.23.0rc0) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx->nemo_toolkit==1.23.0rc0) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx->nemo_toolkit==1.23.0rc0) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from sphinx->nemo_toolkit==1.23.0rc0) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx->nemo_toolkit==1.23.0rc0) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.11/dist-packages (from sphinx->nemo_toolkit==1.23.0rc0) (2.0.0)\n",
            "Requirement already satisfied: docutils<0.22,>=0.20 in /usr/local/lib/python3.11/dist-packages (from sphinx->nemo_toolkit==1.23.0rc0) (0.21.2)\n",
            "Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.11/dist-packages (from sphinx->nemo_toolkit==1.23.0rc0) (3.0.1)\n",
            "Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.11/dist-packages (from sphinx->nemo_toolkit==1.23.0rc0) (2.17.0)\n",
            "Requirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.11/dist-packages (from sphinx->nemo_toolkit==1.23.0rc0) (1.0.0)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.11/dist-packages (from sphinx->nemo_toolkit==1.23.0rc0) (1.4.1)\n",
            "Requirement already satisfied: roman-numerals-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from sphinx->nemo_toolkit==1.23.0rc0) (3.1.0)\n",
            "Collecting pybtex>=0.24 (from sphinxcontrib-bibtex->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading pybtex-0.24.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting pybtex-docutils>=1.0.0 (from sphinxcontrib-bibtex->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading pybtex_docutils-1.0.3-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting latexcodec>=1.0.4 (from pybtex>=0.24->sphinxcontrib-bibtex->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading latexcodec-3.0.1-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nemo_toolkit==1.23.0rc0) (1.73.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nemo_toolkit==1.23.0rc0) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->nemo_toolkit==1.23.0rc0) (0.7.2)\n",
            "Collecting plac (from texterrors->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading plac-1.4.5-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting loguru (from texterrors->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from texterrors->nemo_toolkit==1.23.0rc0) (3.1.0)\n",
            "Collecting Levenshtein (from texterrors->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "INFO: pip is looking at multiple versions of levenshtein to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading levenshtein-0.26.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "  Downloading levenshtein-0.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "  Downloading Levenshtein-0.25.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "  Downloading Levenshtein-0.25.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "  Downloading Levenshtein-0.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "  Downloading Levenshtein-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "  Downloading Levenshtein-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting trampoline>=0.1.2 (from torchsde->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading trampoline-0.1.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->nemo_toolkit==1.23.0rc0) (3.1.44)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb->nemo_toolkit==1.23.0rc0) (2.11.7)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->nemo_toolkit==1.23.0rc0) (2.30.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->nemo_toolkit==1.23.0rc0) (1.3.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->nemo_toolkit==1.23.0rc0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->nemo_toolkit==1.23.0rc0) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->nemo_toolkit==1.23.0rc0) (0.4.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->nemo_toolkit==1.23.0rc0) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->nemo_toolkit==1.23.0rc0) (5.0.2)\n",
            "Collecting donfig>=0.8 (from zarr->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading donfig-0.8.1.post1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting numcodecs>=0.14 (from numcodecs[crc32c]>=0.14->zarr->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading numcodecs-0.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting crc32c>=2.7 (from numcodecs[crc32c]>=0.14->zarr->nemo_toolkit==1.23.0rc0)\n",
            "  Downloading crc32c-2.7.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Downloading black-19.10b0-py36-none-any.whl (97 kB)\n",
            "Downloading click-8.0.2-py3-none-any.whl (97 kB)\n",
            "Downloading huggingface_hub-0.23.2-py3-none-any.whl (401 kB)\n",
            "Downloading megatron_core-0.2.0-py3-none-any.whl (46 kB)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "Downloading isort-5.13.2-py3-none-any.whl (92 kB)\n",
            "Downloading OpenCC-1.1.6-cp311-cp311-manylinux1_x86_64.whl (778 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m778.2/778.2 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading tensorstore-0.1.45-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m125.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diffusers-0.32.2-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiwer-2.5.2-py3-none-any.whl (15 kB)\n",
            "Downloading rapidfuzz-2.13.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lhotse-1.30.3-py3-none-any.whl (851 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m851.4/851.4 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cytoolz-1.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lilcom-1.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "Downloading nerfacc-0.5.3-py3-none-any.whl (54 kB)\n",
            "Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m148.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.1.post0-py3-none-any.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.1/823.1 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading textdistance-4.6.3-py3-none-any.whl (31 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m141.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m143.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m152.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.7.3-py3-none-any.whl (962 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m962.6/962.6 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m134.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typed_ast-1.5.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (860 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m860.3/860.3 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading webdataset-0.2.111-py3-none-any.whl (85 kB)\n",
            "Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
            "Downloading boto3-1.38.38-py3-none-any.whl (139 kB)\n",
            "Downloading botocore-1.38.38-py3-none-any.whl (13.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m142.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.13.0-py3-none-any.whl (85 kB)\n",
            "Downloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
            "Downloading einops_exts-0.0.4-py3-none-any.whl (3.9 kB)\n",
            "Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "Downloading Flask_RESTful-0.3.10-py2.py3-none-any.whl (26 kB)\n",
            "Downloading aniso8601-10.0.1-py2.py3-none-any.whl (52 kB)\n",
            "Downloading Flask-2.2.5-py3-none-any.whl (101 kB)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "Downloading g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ijson-3.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (134 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kaldiio-2.18.1-py3-none-any.whl (29 kB)\n",
            "Downloading kornia-0.8.1-py2.py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia_rs-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdown2-2.5.3-py3-none-any.whl (48 kB)\n",
            "Downloading marshmallow-4.0.0-py3-none-any.whl (48 kB)\n",
            "Downloading nemo_text_processing-1.1.0-py3-none-any.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynini-2.1.6.post1-cp311-cp311-manylinux_2_28_x86_64.whl (154.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading open_clip_torch-2.32.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pangu-4.0.6.1-py3-none-any.whl (6.4 kB)\n",
            "Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Downloading pyannote.core-5.0.0-py3-none-any.whl (58 kB)\n",
            "Downloading pyannote.metrics-3.2.1-py3-none-any.whl (51 kB)\n",
            "Downloading pyannote.database-5.1.3-py3-none-any.whl (48 kB)\n",
            "Downloading pyloudnorm-0.1.1-py3-none-any.whl (9.6 kB)\n",
            "Downloading PyMCubes-0.1.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (336 kB)\n",
            "Downloading pypinyin-0.54.0-py2.py3-none-any.whl (837 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m837.0/837.0 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypinyin_dict-0.9.0-py2.py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest_runner-6.0.1-py3-none-any.whl (7.2 kB)\n",
            "Downloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml-0.18.14-py3-none-any.whl (118 kB)\n",
            "Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Downloading sphinxcontrib_bibtex-2.6.4-py3-none-any.whl (40 kB)\n",
            "Downloading pybtex-0.24.0-py2.py3-none-any.whl (561 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.4/561.4 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading latexcodec-3.0.1-py3-none-any.whl (18 kB)\n",
            "Downloading pybtex_docutils-1.0.3-py3-none-any.whl (6.4 kB)\n",
            "Downloading taming_transformers-0.0.1-py3-none-any.whl (45 kB)\n",
            "Downloading texterrors-1.0.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Levenshtein-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (172 kB)\n",
            "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "Downloading plac-1.4.5-py2.py3-none-any.whl (22 kB)\n",
            "Downloading torchdiffeq-0.2.5-py3-none-any.whl (32 kB)\n",
            "Downloading torchsde-0.2.6-py3-none-any.whl (61 kB)\n",
            "Downloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n",
            "Downloading trimesh-4.6.12-py3-none-any.whl (711 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m712.0/712.0 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zarr-3.0.8-py3-none-any.whl (205 kB)\n",
            "Downloading donfig-0.8.1.post1-py3-none-any.whl (21 kB)\n",
            "Downloading numcodecs-0.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m109.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading crc32c-2.7.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "Building wheels for collected packages: nemo_toolkit, intervaltree, progress, clip, fasttext, distance, kaldi-python-io, cdifflib, docopt, rouge_score, sox, wget\n",
            "  Building editable for nemo_toolkit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nemo_toolkit: filename=nemo_toolkit-1.23.0rc0-0.editable-py3-none-any.whl size=10006 sha256=c5abcd46678f06c465a46dade19ccab1110f462cfa9a9e6d103e90c7331f47a9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gszi1et2/wheels/f7/61/56/81d03abe5cfc0128efaa07e365ec3773e379ed86070d99ee8a\n",
            "\u001b[33m  DEPRECATION: Building 'intervaltree' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'intervaltree'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26098 sha256=0e71a397f3eb2ef20ec96faea208ddf9c77f3ded3bebfd1fa2da55ea10cf876b\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/d7/d9/eec6891f78cac19a693bd40ecb8365d2f4613318c145ec9816\n",
            "\u001b[33m  DEPRECATION: Building 'progress' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'progress'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for progress (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progress: filename=progress-1.6-py3-none-any.whl size=9613 sha256=10514d2d468a841cff5cb07b45dada4b854a10035fecdb4ead849be3f3c1ac8c\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/b9/86/f1bcc2a1de592673c4192d9459c0da1100d70212f38b6bd2a4\n",
            "\u001b[33m  DEPRECATION: Building 'clip' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'clip'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-0.2.0-py3-none-any.whl size=6989 sha256=77ef3c84867c8785964037b9bba5588af738935bca4194c4f665a9ef48154f29\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/a5/e8/c9fa20742edbccf2702dae8ee62053e6c460e961d45967b49c\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.3-cp311-cp311-linux_x86_64.whl size=4313511 sha256=2d2e0867c7905e5a8fe7a42e5df7ca3a54847751b5a334b2cfe140a8b836ecd9\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/4f/35/5057db0249224e9ab55a513fa6b79451473ceb7713017823c3\n",
            "\u001b[33m  DEPRECATION: Building 'distance' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'distance'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for distance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for distance: filename=Distance-0.1.3-py3-none-any.whl size=16256 sha256=d7abc1088cdcb49fb05ada3e24ac73d7ecfd75269bd1804e6bde172b94e4a2d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/cd/9c/3ab5d666e3bcacc58900b10959edd3816cc9557c7337986322\n",
            "\u001b[33m  DEPRECATION: Building 'kaldi-python-io' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'kaldi-python-io'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for kaldi-python-io (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaldi-python-io: filename=kaldi_python_io-1.2.2-py3-none-any.whl size=8953 sha256=4ec702a2336f44a55c0466259f536bcb890a3177ce823a7564013209b1b19dc2\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/86/7b/eec1bb7dc63b8aab5da6317609313873e6e75f065b65f3c29c\n",
            "  Building wheel for cdifflib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cdifflib: filename=cdifflib-1.2.9-cp311-cp311-linux_x86_64.whl size=28831 sha256=2d49ce66a5cc312317c3bd4e08a8e75aabc3b6880fa9ab2de1158cf413c529d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/89/fa/9ac6480fd2400e5d7f4795b524c0d241eb8cdb921b72d5d102\n",
            "\u001b[33m  DEPRECATION: Building 'docopt' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'docopt'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=36e285638a9ed8cdd89b8acc5c0ddf5503541cd8eb281a69f6bedfe3b30b87b9\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
            "\u001b[33m  DEPRECATION: Building 'rouge_score' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'rouge_score'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=3f597a997d7c8a8695a93aabff8593199f6051b430e4a17af1612038b310a296\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "\u001b[33m  DEPRECATION: Building 'sox' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'sox'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for sox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sox: filename=sox-1.5.0-py3-none-any.whl size=40036 sha256=ebc7457f3ec44f4a25e6fa01c52654bf5135c49aa16366fed9337d4d0848c641\n",
            "  Stored in directory: /root/.cache/pip/wheels/74/89/93/023fcdacaec4e5471e78b43992515e8500cc2505b307e2e6b7\n",
            "\u001b[33m  DEPRECATION: Building 'wget' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'wget'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=894c992dc634bae78b35981ef4981e62f21d320ff5732494c5cba96a7b97b4fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built nemo_toolkit intervaltree progress clip fasttext distance kaldi-python-io cdifflib docopt rouge_score sox wget\n",
            "Installing collected packages: wget, trampoline, progress, plac, pangu, opencc, docopt, distance, clip, braceexpand, appdirs, aniso8601, addict, webdataset, typed-ast, trimesh, textdistance, tensorstore, sox, ruamel.yaml.clib, rapidfuzz, pytest-runner, pypinyin, pynini, pybind11, portalocker, pathspec, parameterized, onnx, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numcodecs, marshmallow, markdown2, loguru, lilcom, lightning-utilities, latexcodec, kornia_rs, kaldiio, kaldi-python-io, jmespath, jedi, isort, intervaltree, ijson, ftfy, faiss-cpu, einops_exts, donfig, cytoolz, crc32c, colorama, click, cdifflib, attrdict, sacremoses, sacrebleu, ruamel.yaml, resampy, pypinyin-dict, PyMCubes, pyloudnorm, pybtex, pyannote.core, nvidia-cusparse-cu12, nvidia-cudnn-cu12, Levenshtein, jiwer, hydra-core, huggingface_hub, Flask, fasttext, botocore, black, zarr, tokenizers, texterrors, s3transfer, rouge_score, pybtex-docutils, nvidia-cusolver-cu12, g2p_en, flask_restful, diffusers, transformers, sphinxcontrib-bibtex, pyannote.database, boto3, torchsde, torchmetrics, torchdiffeq, pyannote.metrics, nerfacc, nemo_toolkit, nemo_text_processing, megatron_core, lhotse, kornia, pytorch-lightning, taming-transformers, open_clip_torch\n",
            "\u001b[2K  Attempting uninstall: tensorstore\n",
            "\u001b[2K    Found existing installation: tensorstore 0.1.74\n",
            "\u001b[2K    Uninstalling tensorstore-0.1.74:\n",
            "\u001b[2K      Successfully uninstalled tensorstore-0.1.74\n",
            "\u001b[2K  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "\u001b[2K    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-curand-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-cublas-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "\u001b[2K  Attempting uninstall: click\n",
            "\u001b[2K    Found existing installation: click 8.2.1\n",
            "\u001b[2K    Uninstalling click-8.2.1:\n",
            "\u001b[2K      Successfully uninstalled click-8.2.1\n",
            "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "\u001b[2K  Attempting uninstall: huggingface_hub\n",
            "\u001b[2K    Found existing installation: huggingface-hub 0.33.0\n",
            "\u001b[2K    Uninstalling huggingface-hub-0.33.0:\n",
            "\u001b[2K      Successfully uninstalled huggingface-hub-0.33.0\n",
            "\u001b[2K  Attempting uninstall: Flask\n",
            "\u001b[2K    Found existing installation: Flask 3.1.1\n",
            "\u001b[2K    Uninstalling Flask-3.1.1:\n",
            "\u001b[2K      Successfully uninstalled Flask-3.1.1\n",
            "\u001b[2K  Attempting uninstall: tokenizers\n",
            "\u001b[2K    Found existing installation: tokenizers 0.21.1\n",
            "\u001b[2K    Uninstalling tokenizers-0.21.1:\n",
            "\u001b[2K      Successfully uninstalled tokenizers-0.21.1\n",
            "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[2K  Attempting uninstall: diffusers\n",
            "\u001b[2K    Found existing installation: diffusers 0.33.1\n",
            "\u001b[2K    Uninstalling diffusers-0.33.1:\n",
            "\u001b[2K      Successfully uninstalled diffusers-0.33.1\n",
            "\u001b[2K  Attempting uninstall: transformers\n",
            "\u001b[2K    Found existing installation: transformers 4.52.4\n",
            "\u001b[2K    Uninstalling transformers-4.52.4:\n",
            "\u001b[2K      Successfully uninstalled transformers-4.52.4\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107/107\u001b[0m [open_clip_torch]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dask 2024.12.1 requires click>=8.1, but you have click 8.0.2 which is incompatible.\n",
            "dask-cuda 25.2.0 requires click>=8.1, but you have click 8.0.2 which is incompatible.\n",
            "orbax-checkpoint 0.11.15 requires tensorstore>=0.1.71, but you have tensorstore 0.1.45 which is incompatible.\n",
            "peft 0.15.2 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.23.2 which is incompatible.\n",
            "gradio 5.31.0 requires huggingface-hub>=0.28.1, but you have huggingface-hub 0.23.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Flask-2.2.5 Levenshtein-0.22.0 PyMCubes-0.1.6 addict-2.4.0 aniso8601-10.0.1 appdirs-1.4.4 attrdict-2.0.1 black-19.10b0 boto3-1.38.38 botocore-1.38.38 braceexpand-0.1.7 cdifflib-1.2.9 click-8.0.2 clip-0.2.0 colorama-0.4.6 crc32c-2.7.1 cytoolz-1.0.1 diffusers-0.32.2 distance-0.1.3 docopt-0.6.2 donfig-0.8.1.post1 einops_exts-0.0.4 faiss-cpu-1.11.0 fasttext-0.9.3 flask_restful-0.3.10 ftfy-6.3.1 g2p_en-2.1.0 huggingface_hub-0.23.2 hydra-core-1.3.2 ijson-3.4.0 intervaltree-3.1.0 isort-5.13.2 jedi-0.19.2 jiwer-2.5.2 jmespath-1.0.1 kaldi-python-io-1.2.2 kaldiio-2.18.1 kornia-0.8.1 kornia_rs-0.1.9 latexcodec-3.0.1 lhotse-1.30.3 lightning-utilities-0.14.3 lilcom-1.8.1 loguru-0.7.3 markdown2-2.5.3 marshmallow-4.0.0 megatron_core-0.2.0 nemo_text_processing-1.1.0 nemo_toolkit-1.23.0rc0 nerfacc-0.5.3 numcodecs-0.16.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnx-1.18.0 open_clip_torch-2.32.0 opencc-1.1.6 pangu-4.0.6.1 parameterized-0.9.0 pathspec-0.12.1 plac-1.4.5 portalocker-3.2.0 progress-1.6 pyannote.core-5.0.0 pyannote.database-5.1.3 pyannote.metrics-3.2.1 pybind11-2.13.6 pybtex-0.24.0 pybtex-docutils-1.0.3 pyloudnorm-0.1.1 pynini-2.1.6.post1 pypinyin-0.54.0 pypinyin-dict-0.9.0 pytest-runner-6.0.1 pytorch-lightning-2.5.1.post0 rapidfuzz-2.13.7 resampy-0.4.3 rouge_score-0.1.2 ruamel.yaml-0.18.14 ruamel.yaml.clib-0.2.12 s3transfer-0.13.0 sacrebleu-2.5.1 sacremoses-0.1.1 sox-1.5.0 sphinxcontrib-bibtex-2.6.4 taming-transformers-0.0.1 tensorstore-0.1.45 textdistance-4.6.3 texterrors-1.0.9 tokenizers-0.20.3 torchdiffeq-0.2.5 torchmetrics-1.7.3 torchsde-0.2.6 trampoline-0.1.2 transformers-4.46.3 trimesh-4.6.12 typed-ast-1.5.5 webdataset-0.2.111 wget-3.2 zarr-3.0.8\n",
            "All done!\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [onnxruntime]\n",
            "\u001b[1A\u001b[2KSuccessfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.22.0\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.11/dist-packages (1.18.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (4.14.0)\n",
            "Collecting onnxmltools\n",
            "  Downloading onnxmltools-1.14.0-py2.py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from onnxmltools) (2.0.2)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.11/dist-packages (from onnxmltools) (1.18.0)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from onnx->onnxmltools) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from onnx->onnxmltools) (4.14.0)\n",
            "Downloading onnxmltools-1.14.0-py2.py3-none-any.whl (352 kB)\n",
            "Installing collected packages: onnxmltools\n",
            "Successfully installed onnxmltools-1.14.0\n",
            "--2025-06-18 17:59:09--  https://github.com/deepanshu-yadav/Quantize_speech_Recognition_For_Hindi/raw/refs/heads/main/file.wav\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/deepanshu-yadav/Quantize_speech_Recognition_For_Hindi/refs/heads/main/file.wav [following]\n",
            "--2025-06-18 17:59:09--  https://raw.githubusercontent.com/deepanshu-yadav/Quantize_speech_Recognition_For_Hindi/refs/heads/main/file.wav\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 677932 (662K) [audio/wav]\n",
            "Saving to: ‘file.wav’\n",
            "\n",
            "file.wav            100%[===================>] 662.04K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-06-18 17:59:10 (11.7 MB/s) - ‘file.wav’ saved [677932/677932]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/AI4Bharat/NeMo.git && cd NeMo && git checkout nemo-v2 && bash reinstall.sh\n",
        "!pip install onnxruntime\n",
        "!pip install onnx\n",
        "!pip install onnxmltools\n",
        "\n",
        "!wget https://github.com/deepanshu-yadav/Quantize_speech_Recognition_For_Hindi/raw/refs/heads/main/file.wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F7pxcIAhTwuL",
        "outputId": "40123cc7-e3a1-4025-e57a-57c109ec9536"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "Collecting numpy==1.26\n",
            "  Downloading numpy-1.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "Downloading numpy-1.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.0 which is incompatible.\n",
            "dask-cuda 25.2.0 requires click>=8.1, but you have click 8.0.2 which is incompatible.\n",
            "orbax-checkpoint 0.11.15 requires tensorstore>=0.1.71, but you have tensorstore 0.1.45 which is incompatible.\n",
            "peft 0.15.2 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.23.2 which is incompatible.\n",
            "gradio 5.31.0 requires huggingface-hub>=0.28.1, but you have huggingface-hub 0.23.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "18e532d340f9410e9688d24b11ed5ce1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxsim\n",
            "  Downloading onnxsim-0.4.36-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.11/dist-packages (from onnxsim) (1.18.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from onnxsim) (13.9.4)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from onnx->onnxsim) (1.26.0)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from onnx->onnxsim) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from onnx->onnxsim) (4.14.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->onnxsim) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->onnxsim) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->onnxsim) (0.1.2)\n",
            "Downloading onnxsim-0.4.36-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnxsim\n",
            "Successfully installed onnxsim-0.4.36\n",
            "Collecting onnxconverter-common\n",
            "  Downloading onnxconverter_common-1.14.0-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from onnxconverter-common) (1.26.0)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.11/dist-packages (from onnxconverter-common) (1.18.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxconverter-common) (24.2)\n",
            "Collecting protobuf==3.20.2 (from onnxconverter-common)\n",
            "  Downloading protobuf-3.20.2-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "INFO: pip is looking at multiple versions of onnx to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting onnx (from onnxconverter-common)\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Downloading onnxconverter_common-1.14.0-py2.py3-none-any.whl (84 kB)\n",
            "Downloading protobuf-3.20.2-py2.py3-none-any.whl (162 kB)\n",
            "Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m121.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, onnx, onnxconverter-common\n",
            "\u001b[2K  Attempting uninstall: protobuf\n",
            "\u001b[2K    Found existing installation: protobuf 5.29.5\n",
            "\u001b[2K    Uninstalling protobuf-5.29.5:\n",
            "\u001b[2K      Successfully uninstalled protobuf-5.29.5\n",
            "\u001b[2K  Attempting uninstall: onnx\n",
            "\u001b[2K    Found existing installation: onnx 1.18.0\n",
            "\u001b[2K    Uninstalling onnx-1.18.0:\n",
            "\u001b[2K      Successfully uninstalled onnx-1.18.0\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [onnxconverter-common]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.2 which is incompatible.\n",
            "orbax-checkpoint 0.11.15 requires tensorstore>=0.1.71, but you have tensorstore 0.1.45 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.2 which is incompatible.\n",
            "tensorflow-metadata 1.17.1 requires protobuf<6.0.0,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.2 which is incompatible.\n",
            "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed onnx-1.17.0 onnxconverter-common-1.14.0 protobuf-3.20.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "f6e948c07ed44361a6f3531005750753"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip uninstall numpy -y\n",
        "!pip install numpy==1.26\n",
        "!pip install onnxsim\n",
        "!pip install onnxconverter-common"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMVtAPvLfpfO"
      },
      "source": [
        "## Restart the session after this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "HwVAwumIIzDM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZylFNVMOry-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "from onnx import shape_inference\n",
        "\n",
        "def print_model(file_name):\n",
        "  # Load and check the ONNX model\n",
        "  onnx_model = onnx.load(file_name)\n",
        "  onnx.checker.check_model(onnx_model)\n",
        "\n",
        "  # Run shape inference to populate shapes\n",
        "  inferred_model = shape_inference.infer_shapes(onnx_model)\n",
        "\n",
        "  # Function to extract input/output shapes\n",
        "  def get_io_shapes(model):\n",
        "      input_shapes = {}\n",
        "      output_shapes = {}\n",
        "\n",
        "      for input_tensor in model.graph.input:\n",
        "          shape = [dim.dim_value if dim.dim_value > 0 else \"?\" for dim in input_tensor.type.tensor_type.shape.dim]\n",
        "          input_shapes[input_tensor.name] = shape\n",
        "\n",
        "      for output_tensor in model.graph.output:\n",
        "          shape = [dim.dim_value if dim.dim_value > 0 else \"?\" for dim in output_tensor.type.tensor_type.shape.dim]\n",
        "          output_shapes[output_tensor.name] = shape\n",
        "\n",
        "      return input_shapes, output_shapes\n",
        "\n",
        "  # Get and print input/output shapes\n",
        "  input_shapes, output_shapes = get_io_shapes(inferred_model)\n",
        "\n",
        "  print(\"Inputs:\")\n",
        "  for name, shape in input_shapes.items():\n",
        "      print(f\"  {name}: {shape}\")\n",
        "\n",
        "  print(\"\\nOutputs:\")\n",
        "  for name, shape in output_shapes.items():\n",
        "      print(f\"  {name}: {shape}\")\n"
      ],
      "metadata": {
        "id": "gz1ICyaq2JL4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from typing import Dict\n",
        "import os\n",
        "import nemo.collections.asr as nemo_asr\n",
        "import onnx\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Load the model\n",
        "print(\"Loading NeMo model...\")\n",
        "# Using a specific revision for reproducibility\n",
        "model = nemo_asr.models.ASRModel.from_pretrained(\n",
        "    \"ai4bharat/indicconformer_stt_hi_hybrid_rnnt_large\",\n",
        ")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.freeze()  # Set to inference mode\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "print(\"✅ Model loaded successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7oMi5TcK6uz",
        "outputId": "3f49af06-70d0-44c6-97dc-4c11831abb9e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading NeMo model...\n",
            "[NeMo I 2025-06-18 18:51:07 nemo_logging:381] _setup_tokenizer: detected an aggregate tokenizer\n",
            "[NeMo I 2025-06-18 18:51:07 nemo_logging:381] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2025-06-18 18:51:07 nemo_logging:381] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2025-06-18 18:51:07 nemo_logging:381] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2025-06-18 18:51:07 nemo_logging:381] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2025-06-18 18:51:07 nemo_logging:381] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2025-06-18 18:51:07 nemo_logging:381] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2025-06-18 18:51:07 nemo_logging:381] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2025-06-18 18:51:07 nemo_logging:381] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2025-06-18 18:51:07 nemo_logging:381] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2025-06-18 18:51:07 nemo_logging:381] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2025-06-18 18:51:07 nemo_logging:381] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2025-06-18 18:51:07 nemo_logging:381] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2025-06-18 18:51:07 nemo_logging:381] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2025-06-18 18:51:07 nemo_logging:381] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2025-06-18 18:51:07 nemo_logging:381] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2025-06-18 18:51:07 nemo_logging:381] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2025-06-18 18:51:07 nemo_logging:381] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2025-06-18 18:51:07 nemo_logging:381] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2025-06-18 18:51:07 nemo_logging:381] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2025-06-18 18:51:07 nemo_logging:381] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2025-06-18 18:51:07 nemo_logging:381] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2025-06-18 18:51:07 nemo_logging:381] Tokenizer SentencePieceTokenizer initialized with 256 tokens\n",
            "[NeMo I 2025-06-18 18:51:07 nemo_logging:381] Aggregate vocab size: 5632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2025-06-18 18:51:14 nemo_logging:393] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
            "    Train config : \n",
            "    manifest_filepath:\n",
            "    - /nlsasfs/home/ai4bharat/ai4bharat-pr/speechteam/indicasr_v3/manifests/nemo/vistaar_v3/train/train_hindi.json\n",
            "    sample_rate: 16000\n",
            "    batch_size: 8\n",
            "    num_workers: 16\n",
            "    pin_memory: true\n",
            "    max_duration: 30.0\n",
            "    min_duration: 0.2\n",
            "    is_tarred: false\n",
            "    tarred_audio_filepaths: null\n",
            "    shuffle_n: 2048\n",
            "    bucketing_strategy: synced_randomized\n",
            "    bucketing_batch_size: null\n",
            "    is_concat: true\n",
            "    concat_sampling_technique: temperature\n",
            "    concat_sampling_temperature: 1.5\n",
            "    return_language_id: true\n",
            "    \n",
            "[NeMo W 2025-06-18 18:51:14 nemo_logging:393] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
            "    Validation config : \n",
            "    manifest_filepath:\n",
            "    - /nlsasfs/home/ai4bharat/ai4bharat-pr/speechteam/indicasr_v3/manifests/nemo/vistaar_v3/valid_datasetwise/valid_hindi_indicvoices.json\n",
            "    sample_rate: 16000\n",
            "    batch_size: 16\n",
            "    shuffle: false\n",
            "    use_start_end_token: false\n",
            "    num_workers: 8\n",
            "    return_language_id: true\n",
            "    pin_memory: true\n",
            "    \n",
            "[NeMo W 2025-06-18 18:51:14 nemo_logging:393] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
            "    Test config : \n",
            "    manifest_filepath: null\n",
            "    sample_rate: 16000\n",
            "    batch_size: 16\n",
            "    shuffle: false\n",
            "    use_start_end_token: false\n",
            "    num_workers: 8\n",
            "    pin_memory: true\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NeMo I 2025-06-18 18:51:14 nemo_logging:381] PADDING: 0\n",
            "[NeMo I 2025-06-18 18:51:18 nemo_logging:381] Vocab size for each language: 256\n",
            "[NeMo I 2025-06-18 18:51:18 nemo_logging:381] Using RNNT Loss : warprnnt_numba\n",
            "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
            "[NeMo I 2025-06-18 18:51:18 nemo_logging:381] Using RNNT Loss : warprnnt_numba\n",
            "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
            "[NeMo I 2025-06-18 18:51:20 nemo_logging:381] Using RNNT Loss : warprnnt_numba\n",
            "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
            "[NeMo I 2025-06-18 18:51:20 nemo_logging:381] Creating masks for multi-softmax layer.\n",
            "[NeMo I 2025-06-18 18:51:20 nemo_logging:381] Using RNNT Loss : warprnnt_numba\n",
            "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
            "[NeMo I 2025-06-18 18:51:21 nemo_logging:381] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /root/.cache/huggingface/hub/models--ai4bharat--indicconformer_stt_hi_hybrid_rnnt_large/snapshots/deada84ce880997c56ee933aa21571d768264700/indicconformer_stt_hi_hybrid_rnnt_large.nemo.\n",
            "✅ Model loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from typing import Dict\n",
        "import os\n",
        "import nemo.collections.asr as nemo_asr\n",
        "import onnx\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "def add_meta_data(filename: str, meta_data: Dict[str, str]):\n",
        "    \"\"\"Add meta data to an ONNX model. It is changed in-place.\n",
        "\n",
        "    Args:\n",
        "      filename:\n",
        "        Filename of the ONNX model to be changed.\n",
        "      meta_data:\n",
        "        Key-value pairs.\n",
        "    \"\"\"\n",
        "    model = onnx.load(filename)\n",
        "    while len(model.metadata_props):\n",
        "        model.metadata_props.pop()\n",
        "\n",
        "    for key, value in meta_data.items():\n",
        "        meta = model.metadata_props.add()\n",
        "        meta.key = key\n",
        "        meta.value = str(value)\n",
        "\n",
        "    onnx.save(model, filename)\n",
        "\n",
        "# Custom wrapper for joint_net to define forward method\n",
        "class JointNetWrapper(nn.Module):\n",
        "    def __init__(self, joint_module, lang_ids):\n",
        "        super(JointNetWrapper, self).__init__()\n",
        "        self.joint_module = joint_module\n",
        "        self.lang_ids = lang_ids\n",
        "\n",
        "    def forward(self, encoder_outputs, decoder_outputs):\n",
        "        encoder_outputs = encoder_outputs.transpose(1, 2)  # (B, T, D)\n",
        "        decoder_outputs = decoder_outputs.transpose(1, 2)\n",
        "        return self.joint_module.joint(encoder_outputs, decoder_outputs, self.lang_ids)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def main():\n",
        "    # Save tokens\n",
        "    with open(\"./tokens.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "      for i, s in enumerate(model.joint.vocabulary):\n",
        "          f.write(f\"{s} {i}\\n\")\n",
        "      f.write(f\"<blk> {i+1}\\n\")\n",
        "    print(\"Saved to tokens.txt\")\n",
        "    model.set_export_config({\"decoder_type\": \"rnnt\", \"cache_support\": False})\n",
        "    # Export encoder and decoder\n",
        "    model.encoder.export(\"encoder.onnx\")\n",
        "    model.decoder.export(\"decoder.onnx\")\n",
        "    print(\"✅ Encoder and decoder exported.\")\n",
        "    model.joint._prepare_for_export()\n",
        "    # Wrap joint_net for export\n",
        "    # joint_wrapper = JointNetWrapper(model.joint, model.joint.language_keys)\n",
        "    joint_wrapper = JointNetWrapper(model.joint, [\"hi\"])\n",
        "    joint_wrapper.eval()\n",
        "\n",
        "    # max_batch = 1\n",
        "    # max_dim = 1\n",
        "    # B, T, U = max_batch, max_dim, max_batch\n",
        "    # encoder_outputs = torch.randn(B, 512, T).to(device)\n",
        "    # decoder_outputs = torch.randn(B, 640, U).to(device)\n",
        "    # input_example =  (encoder_outputs, decoder_outputs)\n",
        "    # print(input_example[0].shape, input_example[1].shape)\n",
        "    input_example = model.joint.input_example()\n",
        "    print(input_example[0].shape, input_example[1].shape)\n",
        "    # Export joint network to ONNX\n",
        "    torch.onnx.export(\n",
        "        joint_wrapper,\n",
        "        #(encoder_output, decoder_output),\n",
        "        input_example,\n",
        "        \"joiner.onnx\",\n",
        "        input_names=[\"encoder_outputs\", \"decoder_outputs\"],\n",
        "        output_names=[\"output\"],\n",
        "        dynamic_axes={\n",
        "        \"encoder_outputs\": {0: \"batch_size\", 2: \"encoder_seq_len\"},  # First and third dimensions\n",
        "        \"decoder_outputs\": {0: \"batch_size\", 2: \"decoder_seq_len\"},  # First and third dimensions\n",
        "        \"output\": {0: \"batch_size\"}  # Output batch dimension\n",
        "        },\n",
        "        opset_version=13, # Using a stable opset version\n",
        "        verbose=False,\n",
        "    )\n",
        "    print(\"✅ Joint network exported to joiner.onnx\")\n",
        "\n",
        "    # Print file sizes\n",
        "    os.system(\"ls -lh *.onnx\")\n",
        "    normalize_type = model.cfg.preprocessor.normalize\n",
        "    if normalize_type == \"NA\":\n",
        "      normalize_type = \"\"\n",
        "    meta_data = {\n",
        "    \"vocab_size\": model.decoder.vocab_size,\n",
        "    \"normalize_type\": normalize_type,\n",
        "    \"pred_rnn_layers\": model.decoder.pred_rnn_layers,\n",
        "    \"pred_hidden\": model.decoder.pred_hidden,\n",
        "    \"subsampling_factor\": 8,\n",
        "    \"model_type\": \"EncDecRNNTBPEModel\",\n",
        "    \"version\": \"2\",\n",
        "    \"model_author\": \"AI4Bharat\",\n",
        "    \"url\": \"https://huggingface.co/ai4bharat/indicconformer_stt_hi_hybrid_ctc_rnnt_large\",\n",
        "    \"comment\": \"Only the transducer branch is exported\",\n",
        "    \"feat_dim\": 80,\n",
        "    }\n",
        "    add_meta_data(\"encoder.onnx\", meta_data)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92hbK73NuHJU",
        "outputId": "ec0d831f-9815-45b7-807c-a9fe001a0a01"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to tokens.txt\n",
            "[NeMo I 2025-06-18 18:51:33 nemo_logging:381] No `decoding_cfg` passed when changing decoding strategy, using internal config\n",
            "[NeMo I 2025-06-18 18:51:33 nemo_logging:381] Using RNNT Loss : warprnnt_numba\n",
            "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
            "[NeMo I 2025-06-18 18:51:33 nemo_logging:381] Changed decoding strategy of the RNNT decoder to \n",
            "    model_type: rnnt\n",
            "    strategy: greedy_batch\n",
            "    compute_hypothesis_token_set: false\n",
            "    preserve_alignments: null\n",
            "    confidence_cfg:\n",
            "      preserve_frame_confidence: false\n",
            "      preserve_token_confidence: false\n",
            "      preserve_word_confidence: false\n",
            "      exclude_blank: true\n",
            "      aggregation: min\n",
            "      method_cfg:\n",
            "        name: entropy\n",
            "        entropy_type: tsallis\n",
            "        alpha: 0.33\n",
            "        entropy_norm: exp\n",
            "        temperature: DEPRECATED\n",
            "    fused_batch_size: null\n",
            "    compute_timestamps: null\n",
            "    compute_langs: false\n",
            "    word_seperator: ' '\n",
            "    rnnt_timestamp_type: all\n",
            "    greedy:\n",
            "      max_symbols_per_step: 10\n",
            "      preserve_alignments: false\n",
            "      preserve_frame_confidence: false\n",
            "      confidence_method_cfg:\n",
            "        name: entropy\n",
            "        entropy_type: tsallis\n",
            "        alpha: 0.33\n",
            "        entropy_norm: exp\n",
            "        temperature: DEPRECATED\n",
            "      loop_labels: false\n",
            "      use_cuda_graph_decoder: false\n",
            "      max_symbols: 10\n",
            "    beam:\n",
            "      beam_size: 2\n",
            "      search_type: default\n",
            "      score_norm: true\n",
            "      return_best_hypothesis: false\n",
            "      tsd_max_sym_exp_per_step: 50\n",
            "      alsd_max_target_len: 2.0\n",
            "      nsc_max_timesteps_expansion: 1\n",
            "      nsc_prefix_alpha: 1\n",
            "      maes_num_steps: 2\n",
            "      maes_prefix_alpha: 1\n",
            "      maes_expansion_gamma: 2.3\n",
            "      maes_expansion_beta: 2\n",
            "      language_model: null\n",
            "      softmax_temperature: 1.0\n",
            "      preserve_alignments: false\n",
            "      ngram_lm_model: null\n",
            "      ngram_lm_alpha: 0.0\n",
            "      hat_subtract_ilm: false\n",
            "      hat_ilm_weight: 0.0\n",
            "      tsd_max_sym_exp: 50\n",
            "    temperature: 1.0\n",
            "    durations: []\n",
            "    big_blank_durations: []\n",
            "    \n",
            "[NeMo I 2025-06-18 18:51:33 nemo_logging:381] Caching support enabled: False\n",
            "(tensor([[[-0.4200,  2.1690,  1.4147,  ..., -0.5191,  0.1904, -0.6599],\n",
            "         [-0.1483, -1.0681,  0.4105,  ..., -1.6017,  0.9347, -1.0683],\n",
            "         [ 1.0736,  1.4031, -0.6934,  ..., -0.2542,  0.2811, -0.0454],\n",
            "         ...,\n",
            "         [ 0.1909,  1.1146, -1.1719,  ..., -0.5311,  1.1849,  0.7657],\n",
            "         [ 0.0893, -0.9829, -0.5380,  ..., -2.1896, -0.2039,  0.4795],\n",
            "         [ 1.0496,  1.2295,  0.8682,  ..., -0.6633, -0.8350, -1.7767]]]), tensor([90]))\n",
            "[NeMo I 2025-06-18 18:51:45 nemo_logging:381] Successfully exported ConformerEncoder to encoder.onnx\n",
            "(tensor([[5632]], dtype=torch.int32), tensor([0], dtype=torch.int32), (tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]), tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])))\n",
            "[NeMo I 2025-06-18 18:51:45 nemo_logging:381] Successfully exported RNNTDecoder to decoder.onnx\n",
            "✅ Encoder and decoder exported.\n",
            "torch.Size([1, 512, 8192]) torch.Size([1, 640, 1])\n",
            "✅ Joint network exported to joiner.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input_example = model.joint.input_example()\n",
        "# model.joint._fuse_loss_wer = False\n",
        "# joint_out = model.joint.forward(encoder_outputs=input_example[0], decoder_outputs=input_example[1], compute_wer=False,language_ids=model.joint.language_keys)\n",
        "# print(joint_out.shape)"
      ],
      "metadata": {
        "id": "sLMiz5qgQwOV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mPSAu0wcU4-W"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "brGF182hbqSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Print Decoder\")\n",
        "print_model(\"decoder.onnx\")\n",
        "print(\"-\"*80)\n",
        "print(\"Enocder contents\")\n",
        "print_model(\"encoder.onnx\")\n",
        "print(\"-\"*80)\n",
        "print(\"Joint cotents\")\n",
        "print_model(\"joiner.onnx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8y5Wjvkxjnv",
        "outputId": "d1f4f694-b262-470a-a81e-e599d43d78e7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Print Decoder\n",
            "Inputs:\n",
            "  targets: ['?', '?']\n",
            "  target_length: ['?']\n",
            "  states.1: [1, '?', 640]\n",
            "  onnx::LSTM_3: [1, 1, 640]\n",
            "\n",
            "Outputs:\n",
            "  outputs: ['?', 640, '?']\n",
            "  prednet_lengths: ['?']\n",
            "  states: [1, '?', 640]\n",
            "  74: [1, '?', 640]\n",
            "--------------------------------------------------------------------------------\n",
            "Enocder contents\n",
            "Inputs:\n",
            "  audio_signal: ['?', 80, '?']\n",
            "  length: ['?']\n",
            "\n",
            "Outputs:\n",
            "  outputs: ['?', 512, '?']\n",
            "  encoded_lengths: ['?']\n",
            "--------------------------------------------------------------------------------\n",
            "Joint cotents\n",
            "Inputs:\n",
            "  encoder_outputs: ['?', 512, '?']\n",
            "  decoder_outputs: ['?', 640, '?']\n",
            "\n",
            "Outputs:\n",
            "  output: ['?', '?', '?', 257]\n",
            "================================================================================\n",
            "Inputs:\n",
            "  targets: ['?', '?']\n",
            "  target_length: ['?']\n",
            "  states.1: [2, '?', 640]\n",
            "  onnx::Slice_3: [2, 1, 640]\n",
            "\n",
            "Outputs:\n",
            "  outputs: ['?', 640, '?']\n",
            "  prednet_lengths: ['?']\n",
            "  states: [2, '?', 640]\n",
            "  162: [2, '?', 640]\n",
            "Inputs:\n",
            "  audio_signal: ['?', 128, '?']\n",
            "  length: ['?']\n",
            "\n",
            "Outputs:\n",
            "  outputs: ['?', 1024, '?']\n",
            "  encoded_lengths: ['?']\n",
            "Inputs:\n",
            "  encoder_outputs: ['?', 1024, '?']\n",
            "  decoder_outputs: ['?', 640, '?']\n",
            "\n",
            "Outputs:\n",
            "  outputs: ['?', '?', '?', 1030]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_0T15h-XyuXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P1p1EfXT9zgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import onnxruntime as ort\n",
        "import soundfile as sf\n",
        "import torch\n",
        "import torchaudio\n",
        "import torchaudio.transforms as T\n",
        "from librosa import resample\n",
        "from typing import Tuple\n",
        "\n",
        "class StandaloneASR:\n",
        "    def __init__(self, model_dir: str = \"model_components\"):\n",
        "        \"\"\"Initialize the transducer-based ASR system.\"\"\"\n",
        "        self.model_dir = model_dir\n",
        "        self.device = \"cuda\" if ort.get_device() == \"GPU\" else \"cpu\"\n",
        "\n",
        "        # Ensure model_dir exists\n",
        "        if not os.path.exists(model_dir):\n",
        "            raise FileNotFoundError(f\"Model directory {model_dir} does not exist\")\n",
        "\n",
        "        # Load ONNX models\n",
        "        encoder_path = os.path.join(model_dir, \"encoder.onnx\")\n",
        "        decoder_path = os.path.join(model_dir, \"decoder.onnx\")\n",
        "        joiner_path = os.path.join(model_dir, \"joiner.onnx\")\n",
        "        for path in [encoder_path, decoder_path, joiner_path]:\n",
        "            if not os.path.exists(path):\n",
        "                raise FileNotFoundError(f\"Model file {path} not found\")\n",
        "\n",
        "        session_opts = ort.SessionOptions()\n",
        "        session_opts.inter_op_num_threads = 1\n",
        "        session_opts.intra_op_num_threads = 1\n",
        "        providers = [\"CUDAExecutionProvider\" if self.device == \"cuda\" else \"CPUExecutionProvider\"]\n",
        "\n",
        "        self.encoder = ort.InferenceSession(encoder_path, sess_options=session_opts, providers=providers)\n",
        "        self.decoder = ort.InferenceSession(decoder_path, sess_options=session_opts, providers=providers)\n",
        "        self.joiner = ort.InferenceSession(joiner_path, sess_options=session_opts, providers=providers)\n",
        "\n",
        "        # Load encoder metadata\n",
        "        meta = self.encoder.get_modelmeta().custom_metadata_map\n",
        "        self.normalize_type = meta.get(\"normalize_type\", \"\")\n",
        "        self.pred_rnn_layers = int(meta.get(\"pred_rnn_layers\", 2))\n",
        "        self.pred_hidden = int(meta.get(\"pred_hidden\", 512))\n",
        "\n",
        "        # Load vocabulary\n",
        "        vocab_path = os.path.join(model_dir, \"tokens.txt\")\n",
        "        if not os.path.exists(vocab_path):\n",
        "            raise FileNotFoundError(f\"Vocab file {vocab_path} not found\")\n",
        "        self.id2token = {}\n",
        "        with open(vocab_path, encoding=\"utf-8\") as f:\n",
        "            for line in f:\n",
        "                t, idx = line.strip().split()\n",
        "                self.id2token[int(idx)] = t\n",
        "        self.blank_id = 256  # No_of_vocab - 1  = 257 - 1\n",
        "\n",
        "    def get_decoder_state(self):\n",
        "        \"\"\"Initialize decoder states.\"\"\"\n",
        "        batch_size = 1\n",
        "        state0 = np.zeros((self.pred_rnn_layers, batch_size, self.pred_hidden), dtype=np.float32)\n",
        "        state1 = np.zeros((self.pred_rnn_layers, batch_size, self.pred_hidden), dtype=np.float32)\n",
        "        return state0, state1\n",
        "\n",
        "    def calculate_audio_features(self, audio: np.ndarray, sr: int) -> np.ndarray:\n",
        "        \"\"\"Compute mel-spectrogram features.\"\"\"\n",
        "        if sr != 16000:\n",
        "            audio = resample(audio, orig_sr=sr, target_sr=16000)\n",
        "\n",
        "        audio = torch.from_numpy(audio).float()\n",
        "        mel_transform = T.MelSpectrogram(\n",
        "            sample_rate=16000,\n",
        "            n_fft=512,\n",
        "            win_length=400,\n",
        "            hop_length=160,\n",
        "            f_min=0.0,\n",
        "            f_max=8000.0,\n",
        "            n_mels=80,\n",
        "            window_fn=torch.hann_window,\n",
        "            power=2.0,\n",
        "            normalized=False\n",
        "        )\n",
        "        audio = audio.unsqueeze(0)\n",
        "        features = mel_transform(audio)\n",
        "        features = torch.log(features + 1e-9)\n",
        "\n",
        "        if self.normalize_type == \"per_feature\":\n",
        "            mean = features.mean(dim=2, keepdims=True)\n",
        "            stddev = features.std(dim=2, keepdims=True) + 1e-5\n",
        "            features = (features - mean) / stddev\n",
        "\n",
        "        features = features.squeeze(0).permute(1, 0).numpy().astype(np.float32)  # [T, n_mels]\n",
        "        return features\n",
        "\n",
        "    def preprocess_audio(self, wav_path: str) -> np.ndarray:\n",
        "        \"\"\"Preprocess WAV file to mel-spectrogram features.\"\"\"\n",
        "        if not os.path.exists(wav_path):\n",
        "            raise FileNotFoundError(f\"WAV file {wav_path} not found\")\n",
        "\n",
        "        audio, sr = sf.read(wav_path, dtype=\"float32\")\n",
        "        if audio.ndim > 1:\n",
        "            audio = audio.mean(axis=1)\n",
        "        audio = np.concatenate([audio, np.zeros(sr * 2)])  # Add 2s padding\n",
        "        return self.calculate_audio_features(audio, sr)\n",
        "\n",
        "    def run_encoder(self, features: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Run encoder on features.\"\"\"\n",
        "        features = torch.from_numpy(features).unsqueeze(0).permute(0, 2, 1)  # [1, n_mels, T]\n",
        "        x_lens = np.array([features.shape[2]], dtype=np.int64)\n",
        "\n",
        "        encoder_out, _ = self.encoder.run(\n",
        "            [self.encoder.get_outputs()[0].name, self.encoder.get_outputs()[1].name],\n",
        "            {\n",
        "                self.encoder.get_inputs()[0].name: features.numpy(),\n",
        "                self.encoder.get_inputs()[1].name: x_lens,\n",
        "            },\n",
        "        )\n",
        "        return encoder_out\n",
        "\n",
        "    def run_decoder(self, token: int, state0: np.ndarray, state1: np.ndarray):\n",
        "        \"\"\"Run decoder for a single token.\"\"\"\n",
        "        target = np.array([[token]], dtype=np.int32)\n",
        "        target_len = np.array([1], dtype=np.int32)\n",
        "\n",
        "        decoder_out, _, state0_next, state1_next = self.decoder.run(\n",
        "            [\n",
        "                self.decoder.get_outputs()[0].name,\n",
        "                self.decoder.get_outputs()[1].name,\n",
        "                self.decoder.get_outputs()[2].name,\n",
        "                self.decoder.get_outputs()[3].name,\n",
        "            ],\n",
        "            {\n",
        "                self.decoder.get_inputs()[0].name: target,\n",
        "                self.decoder.get_inputs()[1].name: target_len,\n",
        "                self.decoder.get_inputs()[2].name: state0,\n",
        "                self.decoder.get_inputs()[3].name: state1,\n",
        "            },\n",
        "        )\n",
        "        return decoder_out, state0_next, state1_next\n",
        "\n",
        "    def run_joiner(self, encoder_out: np.ndarray, decoder_out: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Run joiner to combine encoder and decoder outputs.\"\"\"\n",
        "        logit = self.joiner.run(\n",
        "            [self.joiner.get_outputs()[0].name],\n",
        "            {\n",
        "                self.joiner.get_inputs()[0].name: encoder_out,\n",
        "                self.joiner.get_inputs()[1].name: decoder_out,\n",
        "            },\n",
        "        )[0]\n",
        "        return logit\n",
        "\n",
        "    def transcribe(self, wav_path: str) -> str:\n",
        "        \"\"\"Full transcription pipeline for transducer model.\"\"\"\n",
        "        try:\n",
        "            # Preprocess audio\n",
        "            features = self.preprocess_audio(wav_path)\n",
        "            print(f\"Features shape: {features.shape}\")\n",
        "\n",
        "            # Initialize decoding\n",
        "            ans = [self.blank_id]\n",
        "            state0, state1 = self.get_decoder_state()\n",
        "            decoder_out, state0_next, state1_next = self.run_decoder(ans[-1], state0, state1)\n",
        "\n",
        "            # Run encoder\n",
        "            encoder_out = self.run_encoder(features)\n",
        "            # print(f\"Decoder dimension {decoder_out.shape}\")\n",
        "            # Decode time steps\n",
        "            for t in range(encoder_out.shape[2]):\n",
        "                encoder_out_t = encoder_out[:, :, t : t + 1]\n",
        "                # print(f\"Encoder input to jointnet shape {encoder_out_t.shape}\")\n",
        "                # print(\"=\"*20)\n",
        "                # print(f\"Original Encoder input to jointnet shape {encoder_out.shape}\")\n",
        "                logits = self.run_joiner(encoder_out_t, decoder_out)\n",
        "                logits = torch.from_numpy(logits).squeeze()\n",
        "                idx = torch.argmax(logits, dim=-1).item()\n",
        "                if idx != self.blank_id:\n",
        "                    ans.append(idx)\n",
        "                    state0 = state0_next\n",
        "                    state1 = state1_next\n",
        "                    decoder_out, state0_next, state1_next = self.run_decoder(ans[-1], state0, state1)\n",
        "\n",
        "            # Convert to text\n",
        "            ans = ans[1:]  # Remove initial blank\n",
        "            # print(ans[1:])\n",
        "            tokens = [self.id2token[i+1536] for i in ans]\n",
        "            text = \"\".join(tokens).replace(\"<unk>\", \"\").replace(\"▁\", \" \").strip()\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Transcription failed: {str(e)}\")"
      ],
      "metadata": {
        "id": "7-X6fNP5BXGe"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asr = StandaloneASR(os.getcwd())\n"
      ],
      "metadata": {
        "id": "mY5PfYFSjg52"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asr.transcribe(\"file.wav\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "ywkcLcvNHled",
        "outputId": "32b39104-1694-4378-b32e-e6384b24824f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features shape: (1613, 80)\n",
            "[170, 179, 177, 52, 22, 146, 105, 170, 177, 168, 177, 205, 167, 76, 67, 151, 35, 175, 64, 10, 112, 121, 175, 209, 183, 32, 4, 67, 83, 181, 119, 83, 12, 44, 170, 179, 177, 52, 46, 155, 72, 59, 29, 118, 43, 178, 173, 5, 6, 132, 167, 10, 118, 197, 64, 76, 170, 164, 32, 9, 7, 76, 67, 172, 52, 2, 177, 162, 150, 39, 115, 21, 197, 67, 79, 161, 14, 180, 179, 59, 5, 170, 30, 32, 5, 6, 132, 167, 22, 1, 173, 26, 161, 207, 167, 100, 61, 167]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'शिवपाल की यह टिप्पणी फिल्म कालिया के डायलॉग से मिलतीजुलती है शिवपाल चाहते हैं कि मुलायम पार्टी के मुखिया फिर से बने फिलहाल सपा अध्यक्ष अखिलेश यादव हैं पिता से पार्टी की कमान छीनी थी'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.transcribe([\"file.wav\"], batch_size=1, logprobs=False, language_id='hi')[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIclL7IrKyBj",
        "outputId": "75f9e25d-0277-4fb4-d706-6eb7590a0132"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTranscribing:   0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2025-06-18 18:54:02 nemo_logging:393] /content/NeMo/nemo/collections/asr/parts/preprocessing/features.py:417: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "      with torch.cuda.amp.autocast(enabled=False):\n",
            "    \n",
            "Transcribing: 100%|██████████| 1/1 [00:05<00:00,  5.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' शिवपाल की यह टिप्पणी फ़िल्म कालिया के डायलॉग से मिलती जुलती है शिवपाल चाहते हैं कि मुलायम पार्टी के मुखिया फिर से बने फिलहाल सपा अध्यक्ष अखिलेश यादव हैं पिता से पार्टी की कमान छीनी थी']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vdToaSPjOeAz"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The output of the transcriptions match. That's good."
      ],
      "metadata": {
        "id": "h5CpGVehbj5v"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vQXdf6av-zub"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's convert them to float 16"
      ],
      "metadata": {
        "id": "oMbsAFcfcs2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from onnxconverter_common import float16\n",
        "def convert_to_fp16(input_onnx_path, output_onnx_path):\n",
        "    \"\"\"Convert ONNX model to FP16.\"\"\"\n",
        "    print(\"Starting FP16 conversion...\")\n",
        "    model = onnx.load(input_onnx_path)\n",
        "    model_fp16 = float16.convert_float_to_float16(model)\n",
        "    onnx.save(model_fp16, output_onnx_path)\n",
        "    print(f\"FP16 model saved to {output_onnx_path}\")"
      ],
      "metadata": {
        "id": "JdHPqG2o-zxC"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert_to_fp16(\"encoder.onnx\", \"encoder_fp16.onnx\")\n",
        "convert_to_fp16(\"decoder.onnx\", \"decoder_fp16.onnx\")\n",
        "convert_to_fp16(\"joiner.onnx\", \"joiner_fp16.onnx\")"
      ],
      "metadata": {
        "id": "Z29duT9G-zz0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c93b4fc-c87c-40ad-ce14-c2e4261280b2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting FP16 conversion...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2025-06-18 19:11:11 nemo_logging:393] /usr/local/lib/python3.11/dist-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -8.581150900965895e-09 will be truncated to -1e-07\n",
            "      warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
            "    \n",
            "[NeMo W 2025-06-18 19:11:11 nemo_logging:393] /usr/local/lib/python3.11/dist-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -1.5832484212552345e-09 will be truncated to -1e-07\n",
            "      warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
            "    \n",
            "[NeMo W 2025-06-18 19:11:11 nemo_logging:393] /usr/local/lib/python3.11/dist-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 3.1460729132959386e-08 will be truncated to 1e-07\n",
            "      warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
            "    \n",
            "[NeMo W 2025-06-18 19:11:11 nemo_logging:393] /usr/local/lib/python3.11/dist-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 2.7789894829766126e-08 will be truncated to 1e-07\n",
            "      warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
            "    \n",
            "[NeMo W 2025-06-18 19:11:12 nemo_logging:393] /usr/local/lib/python3.11/dist-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 1.4870000786260107e-09 will be truncated to 1e-07\n",
            "      warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
            "    \n",
            "[NeMo W 2025-06-18 19:11:12 nemo_logging:393] /usr/local/lib/python3.11/dist-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -3.219718103242286e-10 will be truncated to -1e-07\n",
            "      warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
            "    \n",
            "[NeMo W 2025-06-18 19:11:12 nemo_logging:393] /usr/local/lib/python3.11/dist-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 3.301538598066145e-08 will be truncated to 1e-07\n",
            "      warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
            "    \n",
            "[NeMo W 2025-06-18 19:11:12 nemo_logging:393] /usr/local/lib/python3.11/dist-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 6.495974957942963e-08 will be truncated to 1e-07\n",
            "      warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
            "    \n",
            "[NeMo W 2025-06-18 19:11:12 nemo_logging:393] /usr/local/lib/python3.11/dist-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -1.1734664795426397e-08 will be truncated to -1e-07\n",
            "      warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
            "    \n",
            "[NeMo W 2025-06-18 19:11:12 nemo_logging:393] /usr/local/lib/python3.11/dist-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -7.427297532558441e-08 will be truncated to -1e-07\n",
            "      warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
            "    \n",
            "[NeMo W 2025-06-18 19:11:13 nemo_logging:393] /usr/local/lib/python3.11/dist-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 9.671784795273197e-08 will be truncated to 1e-07\n",
            "      warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
            "    \n",
            "[NeMo W 2025-06-18 19:11:14 nemo_logging:393] /usr/local/lib/python3.11/dist-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -2.1164305863408117e-08 will be truncated to -1e-07\n",
            "      warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
            "    \n",
            "[NeMo W 2025-06-18 19:11:15 nemo_logging:393] /usr/local/lib/python3.11/dist-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -5.4016709327697754e-08 will be truncated to -1e-07\n",
            "      warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
            "    \n",
            "[NeMo W 2025-06-18 19:11:15 nemo_logging:393] /usr/local/lib/python3.11/dist-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -9.322538829792393e-08 will be truncated to -1e-07\n",
            "      warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
            "    \n",
            "[NeMo W 2025-06-18 19:11:15 nemo_logging:393] /usr/local/lib/python3.11/dist-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -6.379559636116028e-08 will be truncated to -1e-07\n",
            "      warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
            "    \n",
            "[NeMo W 2025-06-18 19:11:16 nemo_logging:393] /usr/local/lib/python3.11/dist-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -5.327165197854811e-08 will be truncated to -1e-07\n",
            "      warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
            "    \n",
            "[NeMo W 2025-06-18 19:11:16 nemo_logging:393] /usr/local/lib/python3.11/dist-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 5.2899121527616444e-08 will be truncated to 1e-07\n",
            "      warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
            "    \n",
            "[NeMo W 2025-06-18 19:11:16 nemo_logging:393] /usr/local/lib/python3.11/dist-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 4.98257577419281e-08 will be truncated to 1e-07\n",
            "      warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
            "    \n",
            "[NeMo W 2025-06-18 19:11:16 nemo_logging:393] /usr/local/lib/python3.11/dist-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 8.400529338814522e-08 will be truncated to 1e-07\n",
            "      warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
            "    \n",
            "[NeMo W 2025-06-18 19:11:16 nemo_logging:393] /usr/local/lib/python3.11/dist-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 8.158385611523045e-08 will be truncated to 1e-07\n",
            "      warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
            "    \n",
            "[NeMo W 2025-06-18 19:11:17 nemo_logging:393] /usr/local/lib/python3.11/dist-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -5.140900682931715e-08 will be truncated to -1e-07\n",
            "      warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
            "    \n",
            "[NeMo W 2025-06-18 19:11:18 nemo_logging:393] /usr/local/lib/python3.11/dist-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -1.6950071568544445e-08 will be truncated to -1e-07\n",
            "      warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
            "    \n",
            "[NeMo W 2025-06-18 19:11:18 nemo_logging:393] /usr/local/lib/python3.11/dist-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 5.927868329536068e-08 will be truncated to 1e-07\n",
            "      warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
            "    \n",
            "[NeMo W 2025-06-18 19:11:18 nemo_logging:393] /usr/local/lib/python3.11/dist-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -6.824266307603466e-08 will be truncated to -1e-07\n",
            "      warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
            "    \n",
            "[NeMo W 2025-06-18 19:11:19 nemo_logging:393] /usr/local/lib/python3.11/dist-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 4.377216100692749e-08 will be truncated to 1e-07\n",
            "      warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
            "    \n",
            "[NeMo W 2025-06-18 19:11:19 nemo_logging:393] /usr/local/lib/python3.11/dist-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -3.231689404969984e-08 will be truncated to -1e-07\n",
            "      warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
            "    \n",
            "[NeMo W 2025-06-18 19:11:20 nemo_logging:393] /usr/local/lib/python3.11/dist-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 1.844018626684374e-08 will be truncated to 1e-07\n",
            "      warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
            "    \n",
            "[NeMo W 2025-06-18 19:11:20 nemo_logging:393] /usr/local/lib/python3.11/dist-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 2.942979371312049e-08 will be truncated to 1e-07\n",
            "      warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
            "    \n",
            "[NeMo W 2025-06-18 19:11:20 nemo_logging:393] /usr/local/lib/python3.11/dist-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -1.05923394499996e-08 will be truncated to -1e-07\n",
            "      warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
            "    \n",
            "[NeMo W 2025-06-18 19:11:21 nemo_logging:393] /usr/local/lib/python3.11/dist-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -4.647299789439785e-08 will be truncated to -1e-07\n",
            "      warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
            "    \n",
            "[NeMo W 2025-06-18 19:11:21 nemo_logging:393] /usr/local/lib/python3.11/dist-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 8.996575928676975e-08 will be truncated to 1e-07\n",
            "      warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
            "    \n",
            "[NeMo W 2025-06-18 19:11:21 nemo_logging:393] /usr/local/lib/python3.11/dist-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 4.132743924856186e-09 will be truncated to 1e-07\n",
            "      warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
            "    \n",
            "[NeMo W 2025-06-18 19:11:22 nemo_logging:393] /usr/local/lib/python3.11/dist-packages/onnxconverter_common/float16.py:50: UserWarning: the float32 number -10000.0 will be truncated to -10000.0\n",
            "      warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_min, -max_finite_val))\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FP16 model saved to encoder_fp16.onnx\n",
            "Starting FP16 conversion...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NeMo W 2025-06-18 19:11:32 nemo_logging:393] /usr/local/lib/python3.11/dist-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -8.146412966425487e-08 will be truncated to -1e-07\n",
            "      warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
            "    \n",
            "[NeMo W 2025-06-18 19:11:32 nemo_logging:393] /usr/local/lib/python3.11/dist-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 5.597248531330479e-08 will be truncated to 1e-07\n",
            "      warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
            "    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FP16 model saved to decoder_fp16.onnx\n",
            "Starting FP16 conversion...\n",
            "FP16 model saved to joiner_fp16.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import onnxruntime as ort\n",
        "import soundfile as sf\n",
        "import torch\n",
        "import torchaudio\n",
        "import torchaudio.transforms as T\n",
        "from librosa import resample\n",
        "from typing import Tuple\n",
        "\n",
        "class StandaloneASR:\n",
        "    def __init__(self, model_dir: str = \"model_components\"):\n",
        "        \"\"\"Initialize the transducer-based ASR system.\"\"\"\n",
        "        self.model_dir = model_dir\n",
        "        self.device = \"cuda\" if ort.get_device() == \"GPU\" else \"cpu\"\n",
        "\n",
        "        # Ensure model_dir exists\n",
        "        if not os.path.exists(model_dir):\n",
        "            raise FileNotFoundError(f\"Model directory {model_dir} does not exist\")\n",
        "\n",
        "        # Load ONNX models\n",
        "        encoder_path = os.path.join(model_dir, \"encoder_fp16.onnx\")\n",
        "        decoder_path = os.path.join(model_dir, \"decoder_fp16.onnx\")\n",
        "        joiner_path = os.path.join(model_dir, \"joiner_fp16.onnx\")\n",
        "        for path in [encoder_path, decoder_path, joiner_path]:\n",
        "            if not os.path.exists(path):\n",
        "                raise FileNotFoundError(f\"Model file {path} not found\")\n",
        "\n",
        "        session_opts = ort.SessionOptions()\n",
        "        session_opts.inter_op_num_threads = 1\n",
        "        session_opts.intra_op_num_threads = 1\n",
        "        providers = [\"CUDAExecutionProvider\" if self.device == \"cuda\" else \"CPUExecutionProvider\"]\n",
        "\n",
        "        self.encoder = ort.InferenceSession(encoder_path, sess_options=session_opts, providers=providers)\n",
        "        self.decoder = ort.InferenceSession(decoder_path, sess_options=session_opts, providers=providers)\n",
        "        self.joiner = ort.InferenceSession(joiner_path, sess_options=session_opts, providers=providers)\n",
        "\n",
        "        # Load encoder metadata\n",
        "        meta = self.encoder.get_modelmeta().custom_metadata_map\n",
        "        self.normalize_type = meta.get(\"normalize_type\", \"\")\n",
        "        self.pred_rnn_layers = int(meta.get(\"pred_rnn_layers\", 2))\n",
        "        self.pred_hidden = int(meta.get(\"pred_hidden\", 512))\n",
        "\n",
        "        # Load vocabulary\n",
        "        vocab_path = os.path.join(model_dir, \"tokens.txt\")\n",
        "        if not os.path.exists(vocab_path):\n",
        "            raise FileNotFoundError(f\"Vocab file {vocab_path} not found\")\n",
        "        self.id2token = {}\n",
        "        with open(vocab_path, encoding=\"utf-8\") as f:\n",
        "            for line in f:\n",
        "                t, idx = line.strip().split()\n",
        "                self.id2token[int(idx)] = t\n",
        "        self.blank_id = 256  # No_of_vocab - 1  = 257 - 1\n",
        "\n",
        "    def get_decoder_state(self):\n",
        "        \"\"\"Initialize decoder states.\"\"\"\n",
        "        batch_size = 1\n",
        "        state0 = np.zeros((self.pred_rnn_layers, batch_size, self.pred_hidden), dtype=np.float16)\n",
        "        state1 = np.zeros((self.pred_rnn_layers, batch_size, self.pred_hidden), dtype=np.float16)\n",
        "        return state0, state1\n",
        "\n",
        "    def calculate_audio_features(self, audio: np.ndarray, sr: int) -> np.ndarray:\n",
        "        \"\"\"Compute mel-spectrogram features.\"\"\"\n",
        "        if sr != 16000:\n",
        "            audio = resample(audio, orig_sr=sr, target_sr=16000)\n",
        "\n",
        "        audio = torch.from_numpy(audio).float()\n",
        "        mel_transform = T.MelSpectrogram(\n",
        "            sample_rate=16000,\n",
        "            n_fft=512,\n",
        "            win_length=400,\n",
        "            hop_length=160,\n",
        "            f_min=0.0,\n",
        "            f_max=8000.0,\n",
        "            n_mels=80,\n",
        "            window_fn=torch.hann_window,\n",
        "            power=2.0,\n",
        "            normalized=False\n",
        "        )\n",
        "        audio = audio.unsqueeze(0)\n",
        "        features = mel_transform(audio)\n",
        "        features = torch.log(features + 1e-9)\n",
        "\n",
        "        if self.normalize_type == \"per_feature\":\n",
        "            mean = features.mean(dim=2, keepdims=True)\n",
        "            stddev = features.std(dim=2, keepdims=True) + 1e-5\n",
        "            features = (features - mean) / stddev\n",
        "\n",
        "        features = features.squeeze(0).permute(1, 0).numpy().astype(np.float16)  # [T, n_mels]\n",
        "        return features\n",
        "\n",
        "    def preprocess_audio_file(self, wav_path: str) -> np.ndarray:\n",
        "        \"\"\"Preprocess WAV file to mel-spectrogram features.\"\"\"\n",
        "        if not os.path.exists(wav_path):\n",
        "            raise FileNotFoundError(f\"WAV file {wav_path} not found\")\n",
        "\n",
        "        audio, sr = sf.read(wav_path, dtype=\"float32\")\n",
        "        if audio.ndim > 1:\n",
        "            audio = audio.mean(axis=1)\n",
        "        audio = np.concatenate([audio, np.zeros(sr * 2)])  # Add 2s padding\n",
        "        return audio\n",
        "\n",
        "    def run_encoder(self, features: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Run encoder on features.\"\"\"\n",
        "        features = torch.from_numpy(features).unsqueeze(0).permute(0, 2, 1)  # [1, n_mels, T]\n",
        "        x_lens = np.array([features.shape[2]], dtype=np.int64)\n",
        "\n",
        "        encoder_out, _ = self.encoder.run(\n",
        "            [self.encoder.get_outputs()[0].name, self.encoder.get_outputs()[1].name],\n",
        "            {\n",
        "                self.encoder.get_inputs()[0].name: features.numpy(),\n",
        "                self.encoder.get_inputs()[1].name: x_lens,\n",
        "            },\n",
        "        )\n",
        "        return encoder_out\n",
        "\n",
        "    def run_decoder(self, token: int, state0: np.ndarray, state1: np.ndarray):\n",
        "        \"\"\"Run decoder for a single token.\"\"\"\n",
        "        target = np.array([[token]], dtype=np.int32)\n",
        "        target_len = np.array([1], dtype=np.int32)\n",
        "\n",
        "        decoder_out, _, state0_next, state1_next = self.decoder.run(\n",
        "            [\n",
        "                self.decoder.get_outputs()[0].name,\n",
        "                self.decoder.get_outputs()[1].name,\n",
        "                self.decoder.get_outputs()[2].name,\n",
        "                self.decoder.get_outputs()[3].name,\n",
        "            ],\n",
        "            {\n",
        "                self.decoder.get_inputs()[0].name: target,\n",
        "                self.decoder.get_inputs()[1].name: target_len,\n",
        "                self.decoder.get_inputs()[2].name: state0,\n",
        "                self.decoder.get_inputs()[3].name: state1,\n",
        "            },\n",
        "        )\n",
        "        return decoder_out, state0_next, state1_next\n",
        "\n",
        "    def run_joiner(self, encoder_out: np.ndarray, decoder_out: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Run joiner to combine encoder and decoder outputs.\"\"\"\n",
        "        logit = self.joiner.run(\n",
        "            [self.joiner.get_outputs()[0].name],\n",
        "            {\n",
        "                self.joiner.get_inputs()[0].name: encoder_out,\n",
        "                self.joiner.get_inputs()[1].name: decoder_out,\n",
        "            },\n",
        "        )[0]\n",
        "        return logit\n",
        "\n",
        "    def transcribe_file(self, wav_path: str) -> str:\n",
        "        \"\"\"Full transcription pipeline for transducer model.\"\"\"\n",
        "        try:\n",
        "            # Preprocess audio\n",
        "            audio = self.preprocess_audio_file(wav_path)\n",
        "            return self.transcribe(audio)\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Transcription failed: {str(e)}\")\n",
        "\n",
        "    def transcribe(self, audio: np.ndarray) -> str:\n",
        "        \"\"\"Full transcription pipeline for transducer model.\"\"\"\n",
        "        try:\n",
        "            # Preprocess audio\n",
        "            features = self.calculate_audio_features(audio, 16000)\n",
        "            print(f\"Features shape: {features.shape}\")\n",
        "\n",
        "            # Initialize decoding\n",
        "            ans = [self.blank_id]\n",
        "            state0, state1 = self.get_decoder_state()\n",
        "            decoder_out, state0_next, state1_next = self.run_decoder(ans[-1], state0, state1)\n",
        "\n",
        "            # Run encoder\n",
        "            encoder_out = self.run_encoder(features)\n",
        "            # print(f\"Decoder dimension {decoder_out.shape}\")\n",
        "            # Decode time steps\n",
        "            for t in range(encoder_out.shape[2]):\n",
        "                encoder_out_t = encoder_out[:, :, t : t + 1]\n",
        "                # print(f\"Encoder input to jointnet shape {encoder_out_t.shape}\")\n",
        "                # print(\"=\"*20)\n",
        "                # print(f\"Original Encoder input to jointnet shape {encoder_out.shape}\")\n",
        "                logits = self.run_joiner(encoder_out_t, decoder_out)\n",
        "                logits = torch.from_numpy(logits).squeeze()\n",
        "                idx = torch.argmax(logits, dim=-1).item()\n",
        "                if idx != self.blank_id:\n",
        "                    ans.append(idx)\n",
        "                    state0 = state0_next\n",
        "                    state1 = state1_next\n",
        "                    decoder_out, state0_next, state1_next = self.run_decoder(ans[-1], state0, state1)\n",
        "\n",
        "            # Convert to text\n",
        "            ans = ans[1:]  # Remove initial blank\n",
        "            # print(ans[1:])\n",
        "            tokens = [self.id2token[i+1536] for i in ans]\n",
        "            text = \"\".join(tokens).replace(\"<unk>\", \"\").replace(\"▁\", \" \").strip()\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Transcription failed: {str(e)}\")"
      ],
      "metadata": {
        "id": "9g5XFFxl-z2j"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asr = StandaloneASR(os.getcwd())"
      ],
      "metadata": {
        "id": "zzzLl6jmegs8"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(asr.transcribe_file(\"file.wav\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pddr0j2egzS",
        "outputId": "dfc7e0df-2d1b-4a8d-9985-22cc7100318c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features shape: (2419, 80)\n",
            "शिवपाल की यह टिप्पणी फिल्म कालिया के डायलॉग से मिलतीजुलती है शिवपाल चाहते हैं कि मुलायम पार्टी के मुखिया फिर से बने फिलहाल सपा अध्यक्ष अखिलेश यादव हैं पिता से पार्टी की कमान छीनी थी\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FiGM4bnKe00A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fg5hOOG0e03J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Oe3KvpiEeu-k"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}